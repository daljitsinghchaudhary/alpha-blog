"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const util_1 = require("util");
const Token = require("./token");
const addTrailingNewline = (s) => (s.endsWith('\n') ? s : `${s}\n`);
const Lexer = require('lex');
var SC;
(function (SC) {
    SC[SC["Init"] = 0] = "Init";
    SC[SC["Machine"] = 1] = "Machine";
})(SC || (SC = {}));
function lex(body) {
    body = addTrailingNewline(body);
    let tokens = [];
    let lexer = new Lexer((char) => {
        throw new Error(`Unexpected character during netrc parsing. char: ${util_1.inspect(char)}:
${body}`);
    });
    lexer.addRule(/\s*\n/, function (content) {
        this.state = SC.Init;
        tokens.push({ type: 'newline', content });
    }, [SC.Init, SC.Machine]);
    lexer.addRule(/\s*(#.*)\n/, function (content) {
        tokens.push({ type: 'comment', content });
    }, [SC.Init, SC.Machine]);
    lexer.addRule(/([ \t]*)macdef.*\n(.*\S.+(\n|$))*/, function (content) {
        tokens.push({ type: 'macdef', content });
    }, [SC.Init, SC.Machine]);
    lexer.addRule(/([ \t]*)machine +(\S+)([ \t]*\n)?/, function (_, pre, host, post) {
        this.state = SC.Machine;
        tokens.push(new Token.Machine({ host, pre, post }));
    }, [SC.Init, SC.Machine]);
    lexer.addRule(/([ \t]*)default([ \t]*\n)?/, function (_, pre, post) {
        this.state = SC.Machine;
        tokens.push(new Token.DefaultMachine({ pre, post }));
    }, [SC.Init, SC.Machine]);
    lexer.addRule(/([ \t]*)([a-zA-Z]+) +(\S+)([ \t]*\n)?/, (_, pre, name, value, post) => {
        tokens.push(new Token.Prop({ pre, post, name: name, value }));
    }, [SC.Machine]);
    lexer.setInput(body).lex();
    return tokens;
}
exports.default = lex;
